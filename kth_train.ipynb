{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":28,"metadata":{"id":"_YXxmUS4M3Mg","executionInfo":{"status":"ok","timestamp":1666667992046,"user_tz":-390,"elapsed":570,"user":{"displayName":"Khin Thet Htar","userId":"14740449026235859013"}}},"outputs":[],"source":["from IPython import display"]},{"cell_type":"code","source":["!pip install -e transformers\n","!pip install datasets\n","!pip install sentencepiece\n","!pip install git+https://github.com/huggingface/transformers\n","\n","display.clear_output()"],"metadata":{"id":"ad7qW1ZsNCwC","executionInfo":{"status":"ok","timestamp":1666668032948,"user_tz":-390,"elapsed":38313,"user":{"displayName":"Khin Thet Htar","userId":"14740449026235859013"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4aVFSIzJO2oo","executionInfo":{"status":"ok","timestamp":1666668048087,"user_tz":-390,"elapsed":3343,"user":{"displayName":"Khin Thet Htar","userId":"14740449026235859013"}},"outputId":"9aa711f4-aeac-41db-da9d-02b20e7caee8"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["train_file_path = '/content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/transformers-main/examples/pytorch/language-modeling/run_clm.py'\n","model_name = 'rinna/japanese-gpt-1b'\n","\n","train_data = '/content/drive/MyDrive/rinna_testing/Corpus/all/4_categories_20000.txt'\n","train_epochs = 5\n","\n","train_bs = 1\n","\n","val_data = '/content/drive/MyDrive/rinna_testing/Corpus/all/4_categories_20000.txt'\n","val_bs = 1\n","\n","output_path = '/content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/Model/all/11_categories/train-1'"],"metadata":{"id":"lUeO6FgJNEqC","executionInfo":{"status":"ok","timestamp":1666667849235,"user_tz":-390,"elapsed":2,"user":{"displayName":"Khin Thet Htar","userId":"14740449026235859013"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#import gc\n","#gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Af1hSY8DNILX","executionInfo":{"status":"ok","timestamp":1666667857061,"user_tz":-390,"elapsed":2,"user":{"displayName":"Khin Thet Htar","userId":"14740449026235859013"}},"outputId":"48852981-e3c0-4f42-9434-12a975e7c72f"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["44"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["!python {train_file_path} \\\n","    --overwrite_output_dir \\\n","    --model_name_or_path={model_name} \\\n","    --train_file={train_data} \\\n","    --validation_file={val_data} \\\n","    --do_train \\\n","    --do_eval \\\n","    --num_train_epochs={train_epochs} \\\n","    --save_steps=10000 \\\n","    --save_total_limit=3 \\\n","    --per_device_train_batch_size={train_bs} \\\n","    --per_device_eval_batch_size={val_bs} \\\n","    --output_dir={output_path} \\\n","    --use_fast_tokenizer=True"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qsmuS5bUNIhI","outputId":"df3ea64c-d177-4fbb-c466-3bdad1c0ca3a","executionInfo":{"status":"ok","timestamp":1666667952493,"user_tz":-390,"elapsed":93515,"user":{"displayName":"Khin Thet Htar","userId":"14740449026235859013"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/rinna_testing/Corpus/all/4_categories_20000.txt\n","WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n","INFO:__main__:Training/evaluation parameters TrainingArguments(\n","_n_gpu=1,\n","adafactor=False,\n","adam_beta1=0.9,\n","adam_beta2=0.999,\n","adam_epsilon=1e-08,\n","auto_find_batch_size=False,\n","bf16=False,\n","bf16_full_eval=False,\n","data_seed=None,\n","dataloader_drop_last=False,\n","dataloader_num_workers=0,\n","dataloader_pin_memory=True,\n","ddp_bucket_cap_mb=None,\n","ddp_find_unused_parameters=None,\n","ddp_timeout=1800,\n","debug=[],\n","deepspeed=None,\n","disable_tqdm=False,\n","do_eval=True,\n","do_predict=False,\n","do_train=True,\n","eval_accumulation_steps=None,\n","eval_delay=0,\n","eval_steps=None,\n","evaluation_strategy=no,\n","fp16=False,\n","fp16_backend=auto,\n","fp16_full_eval=False,\n","fp16_opt_level=O1,\n","fsdp=[],\n","fsdp_min_num_params=0,\n","fsdp_transformer_layer_cls_to_wrap=None,\n","full_determinism=False,\n","gradient_accumulation_steps=1,\n","gradient_checkpointing=False,\n","greater_is_better=None,\n","group_by_length=False,\n","half_precision_backend=auto,\n","hub_model_id=None,\n","hub_private_repo=False,\n","hub_strategy=every_save,\n","hub_token=<HUB_TOKEN>,\n","ignore_data_skip=False,\n","include_inputs_for_metrics=False,\n","jit_mode_eval=False,\n","label_names=None,\n","label_smoothing_factor=0.0,\n","learning_rate=5e-05,\n","length_column_name=length,\n","load_best_model_at_end=False,\n","local_rank=-1,\n","log_level=passive,\n","log_level_replica=passive,\n","log_on_each_node=True,\n","logging_dir=/content/drive/MyDrive/General Purpose Web Scraping Tool/rinna_testing/Model/all/11_categories/train-1/runs/Oct25_03-20-28_bc2ff6488b91,\n","logging_first_step=False,\n","logging_nan_inf_filter=True,\n","logging_steps=500,\n","logging_strategy=steps,\n","lr_scheduler_type=linear,\n","max_grad_norm=1.0,\n","max_steps=-1,\n","metric_for_best_model=None,\n","mp_parameters=,\n","no_cuda=False,\n","num_train_epochs=5.0,\n","optim=adamw_hf,\n","output_dir=/content/drive/MyDrive/General Purpose Web Scraping Tool/rinna_testing/Model/all/11_categories/train-1,\n","overwrite_output_dir=True,\n","past_index=-1,\n","per_device_eval_batch_size=1,\n","per_device_train_batch_size=1,\n","prediction_loss_only=False,\n","push_to_hub=False,\n","push_to_hub_model_id=None,\n","push_to_hub_organization=None,\n","push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n","ray_scope=last,\n","remove_unused_columns=True,\n","report_to=['tensorboard'],\n","resume_from_checkpoint=None,\n","run_name=/content/drive/MyDrive/General Purpose Web Scraping Tool/rinna_testing/Model/all/11_categories/train-1,\n","save_on_each_node=False,\n","save_steps=10000,\n","save_strategy=steps,\n","save_total_limit=3,\n","seed=42,\n","sharded_ddp=[],\n","skip_memory_metrics=True,\n","tf32=None,\n","torchdynamo=None,\n","tpu_metrics_debug=False,\n","tpu_num_cores=None,\n","use_ipex=False,\n","use_legacy_prediction_loop=False,\n","use_mps_device=False,\n","warmup_ratio=0.0,\n","warmup_steps=0,\n","weight_decay=0.0,\n","xpu_backend=None,\n",")\n","WARNING:datasets.builder:Using custom data configuration default-269a4dd24482d532\n","INFO:datasets.info:Loading Dataset Infos from /usr/local/lib/python3.7/dist-packages/datasets/packaged_modules/text\n","INFO:datasets.builder:Generating dataset text (/root/.cache/huggingface/datasets/text/default-269a4dd24482d532/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad)\n","Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-269a4dd24482d532/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad...\n","Downloading data files: 100% 2/2 [00:00<00:00, 2208.69it/s]\n","INFO:datasets.download.download_manager:Downloading took 0.0 min\n","INFO:datasets.download.download_manager:Checksum Computation took 0.0 min\n","Extracting data files: 100% 2/2 [00:00<00:00, 117.16it/s]\n","INFO:datasets.utils.info_utils:Unable to verify checksums.\n","INFO:datasets.builder:Generating train split\n","INFO:datasets.builder:Generating validation split\n","INFO:datasets.utils.info_utils:Unable to verify splits sizes.\n","Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-269a4dd24482d532/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad. Subsequent calls will reuse this data.\n","100% 2/2 [00:00<00:00, 765.94it/s]\n","[INFO|configuration_utils.py:653] 2022-10-25 03:20:33,084 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt-1b/snapshots/a3c6e8478d5afa92fe5174b984555e01fe378cd3/config.json\n","[INFO|configuration_utils.py:705] 2022-10-25 03:20:33,085 >> Model config GPT2Config {\n","  \"_name_or_path\": \"rinna/japanese-gpt-1b\",\n","  \"activation_function\": \"gelu_fast\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 2,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 3,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 2048,\n","  \"n_head\": 16,\n","  \"n_inner\": 8192,\n","  \"n_layer\": 24,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"transformers_version\": \"4.24.0.dev0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 44928\n","}\n","\n","[INFO|tokenization_utils_base.py:1775] 2022-10-25 03:20:34,045 >> loading file spiece.model from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt-1b/snapshots/a3c6e8478d5afa92fe5174b984555e01fe378cd3/spiece.model\n","[INFO|tokenization_utils_base.py:1775] 2022-10-25 03:20:34,046 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:1775] 2022-10-25 03:20:34,046 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt-1b/snapshots/a3c6e8478d5afa92fe5174b984555e01fe378cd3/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:1775] 2022-10-25 03:20:34,046 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt-1b/snapshots/a3c6e8478d5afa92fe5174b984555e01fe378cd3/tokenizer_config.json\n","[INFO|modeling_utils.py:2156] 2022-10-25 03:20:34,067 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--rinna--japanese-gpt-1b/snapshots/a3c6e8478d5afa92fe5174b984555e01fe378cd3/pytorch_model.bin\n","[INFO|modeling_utils.py:2606] 2022-10-25 03:21:02,139 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","[INFO|modeling_utils.py:2615] 2022-10-25 03:21:02,139 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at rinna/japanese-gpt-1b.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n","Running tokenizer on dataset:   0% 0/128 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/text/default-269a4dd24482d532/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad/cache-ddd30779727a4a96.arrow\n","Running tokenizer on dataset:  99% 127/128 [00:17<00:00,  7.21ba/s]\n","Running tokenizer on dataset:   0% 0/128 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/text/default-269a4dd24482d532/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad/cache-d7015fa3bd28585d.arrow\n","Running tokenizer on dataset:  99% 127/128 [00:18<00:00,  7.01ba/s]\n","WARNING:__main__:The tokenizer picked seems to have a very large `model_max_length` (1000000000000000019884624838656). Picking 1024 instead. You can change that default value by passing --block_size xxx.\n","Grouping texts in chunks of 1024:   0% 0/128 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/text/default-269a4dd24482d532/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad/cache-afe0c2248010f727.arrow\n","Grouping texts in chunks of 1024:  99% 127/128 [00:03<00:00, 34.74ba/s]\n","Grouping texts in chunks of 1024:   0% 0/128 [00:00<?, ?ba/s]INFO:datasets.arrow_dataset:Caching processed dataset at /root/.cache/huggingface/datasets/text/default-269a4dd24482d532/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad/cache-a2b4838a8dda8925.arrow\n","Grouping texts in chunks of 1024:  99% 127/128 [00:03<00:00, 32.91ba/s]\n","/content/drive/MyDrive/General Purpose Web Scraping Tool/rinna_testing/transformers-main/examples/pytorch/language-modeling/run_clm.py:494: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric = load_metric(\"accuracy\")\n","/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","[INFO|trainer.py:1607] 2022-10-25 03:21:52,028 >> ***** Running training *****\n","[INFO|trainer.py:1608] 2022-10-25 03:21:52,028 >>   Num examples = 3132\n","[INFO|trainer.py:1609] 2022-10-25 03:21:52,028 >>   Num Epochs = 5\n","[INFO|trainer.py:1610] 2022-10-25 03:21:52,028 >>   Instantaneous batch size per device = 1\n","[INFO|trainer.py:1611] 2022-10-25 03:21:52,028 >>   Total train batch size (w. parallel, distributed & accumulation) = 1\n","[INFO|trainer.py:1612] 2022-10-25 03:21:52,028 >>   Gradient Accumulation steps = 1\n","[INFO|trainer.py:1613] 2022-10-25 03:21:52,028 >>   Total optimization steps = 15660\n","[INFO|trainer.py:1615] 2022-10-25 03:21:52,029 >>   Number of trainable parameters = 1302605824\n","  0% 0/15660 [00:00<?, ?it/s]Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/General Purpose Web Scraping Tool/rinna_testing/transformers-main/examples/pytorch/language-modeling/run_clm.py\", line 578, in <module>\n","    main()\n","  File \"/content/drive/MyDrive/General Purpose Web Scraping Tool/rinna_testing/transformers-main/examples/pytorch/language-modeling/run_clm.py\", line 526, in main\n","    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1504, in train\n","    ignore_keys_for_eval=ignore_keys_for_eval,\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1745, in _inner_training_loop\n","    tr_loss_step = self.training_step(model, inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 2504, in training_step\n","    loss = self.compute_loss(model, inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 2536, in compute_loss\n","    outputs = model(**inputs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 1059, in forward\n","    return_dict=return_dict,\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 897, in forward\n","    output_attentions=output_attentions,\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 426, in forward\n","    feed_forward_hidden_states = self.mlp(hidden_states)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/gpt2/modeling_gpt2.py\", line 354, in forward\n","    hidden_states = self.act(hidden_states)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/transformers/activations.py\", line 66, in forward\n","    return 0.5 * input * (1.0 + torch.tanh(input * 0.7978845608 * (1.0 + 0.044715 * input * input)))\n","RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 14.76 GiB total capacity; 13.90 GiB already allocated; 7.75 MiB free; 13.95 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n","  0% 0/15660 [00:01<?, ?it/s]\n"]}]},{"cell_type":"code","source":["!pip install huggingface_hub"],"metadata":{"id":"11IMIcs-iK9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBqKwIbRidqd","executionInfo":{"status":"ok","timestamp":1654225892077,"user_tz":-390,"elapsed":29813,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"16ec0485-892c-4f4f-aac3-30b31a0c70f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n","        (Deprecated, will be removed in v0.3.0) To login with username and password instead, interrupt with Ctrl+C.\n","        \n","Token: \n","Login successful\n","Your token has been saved to /root/.huggingface/token\n","\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n","You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n","\n","git config --global credential.helper store\u001b[0m\n"]}]},{"cell_type":"code","source":["!git lfs install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gm9LRFFBihcv","executionInfo":{"status":"ok","timestamp":1654225907576,"user_tz":-390,"elapsed":1348,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"26512920-107a-4c5a-bb37-4fd4b9511354"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n","Git LFS initialized.\n"]}]},{"cell_type":"code","source":["!sudo apt-get install git-lfs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Tv0QCyCjCf5","executionInfo":{"status":"ok","timestamp":1654225952309,"user_tz":-390,"elapsed":2878,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"ee152661-91f0-4b90-89fe-14588846de6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","git-lfs is already the newest version (2.3.4-1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n"]}]},{"cell_type":"code","source":["!git clone https://huggingface.co/CloudSource/rinna-masage-industry"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jfmAdJJ3jFl3","executionInfo":{"status":"ok","timestamp":1654225992389,"user_tz":-390,"elapsed":838,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"9d50a42b-8173-4283-fef5-92bfff1810e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'rinna-masage-industry'...\n","remote: Enumerating objects: 4, done.\u001b[K\n","remote: Counting objects: 100% (4/4), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (4/4), done.\n"]}]},{"cell_type":"code","source":["%cd /content/rinna-massage-industry"],"metadata":{"id":"tKzEXLh002Z-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Massage/nsa/train-1/config.json /content/rinna-masage-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Massage/nsa/train-1/special_tokens_map.json /content/rinna-masage-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Massage/nsa/train-1/spiece.model /content/rinna-masage-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Massage/nsa/train-1/spiece.model /content/rinna-masage-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Massage/nsa/train-1/tokenizer_config.json /content/rinna-masage-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Massage/nsa/train-1/trainer_state.json /content/rinna-masage-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Massage/nsa/train-1/pytorch_model.bin /content/rinna-masage-industry"],"metadata":{"id":"7s0LmNws0Egl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://huggingface.co/CloudSource/rinna-beauty-industry"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7mSERbFXzbKh","executionInfo":{"status":"ok","timestamp":1654230362233,"user_tz":-390,"elapsed":853,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"bef541ae-9ff3-4ef0-d072-2dcb09032d02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'rinna-beauty-industry'...\n","remote: Enumerating objects: 4, done.\u001b[K\n","remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n","remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects:  25% (1/4)   \rUnpacking objects:  50% (2/4)   \rUnpacking objects:  75% (3/4)   \rUnpacking objects: 100% (4/4)   \rUnpacking objects: 100% (4/4), done.\n"]}]},{"cell_type":"code","source":["%cd /content/rinna-beauty-industry"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RpolE0ma0j1i","executionInfo":{"status":"ok","timestamp":1654230522256,"user_tz":-390,"elapsed":515,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"5f39f34a-0924-4ef4-e1b3-f42c567f1352"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/rinna-beauty-industry\n"]}]},{"cell_type":"code","source":["# % cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/config.json /content/rinna-beauty-industry\n","# % cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/special_tokens_map.json /content/rinna-beauty-industry\n","# % cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/spiece.model /content/rinna-beauty-industry\n","# % cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/spiece.model /content/rinna-beauty-industry\n","# % cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/tokenizer_config.json /content/rinna-beauty-industry\n","# % cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/trainer_state.json /content/rinna-beauty-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/pytorch_model.bin /content/rinna-beauty-industry\n","% cp -R /content/drive/MyDrive/General\\ Purpose\\ Web\\ Scraping\\ Tool/rinna_testing/6-1-2022-fine-tune/Beauty/kkkh/Train-2/README.md /content/rinna-beauty-industry"],"metadata":{"id":"AZHO_dnFjXWU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"nyanswanaung436@cloudsource.co.jp\"\n","!git config --global user.name \"CloudSource\""],"metadata":{"id":"r15ij9Y7k6T0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add .\n","!git commit -m 'change model bin'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7J5O4EglCgG","executionInfo":{"status":"ok","timestamp":1654230944018,"user_tz":-390,"elapsed":13120,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"14c3da47-ce57-4a44-ed0d-3f8441bf16f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[main 5082a71] change model bin\n"," 2 files changed, 6 insertions(+), 6 deletions(-)\n"]}]},{"cell_type":"code","source":["username_pw = r'nsa436:BROTHERhood8'"],"metadata":{"id":"NCTvi1JTpowf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push https://{username_pw}@huggingface.co/CloudSource/rinna-beauty-industry"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fq-iL95tlhd-","executionInfo":{"status":"ok","timestamp":1654230973116,"user_tz":-390,"elapsed":21598,"user":{"displayName":"Nyan Swan Aung","userId":"12118485480538526950"}},"outputId":"a95b7afa-e48f-4b04-f722-27e7ccb8a9f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Git LFS: (1 of 1 files, 2 skipped) 1.28 GB / 1.28 GB, 1.28 GB skipped\n","Counting objects: 4, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (4/4), done.\n","Writing objects: 100% (4/4), 502 bytes | 502.00 KiB/s, done.\n","Total 4 (delta 2), reused 0 (delta 0)\n","remote: Enforcing permissions...\u001b[K\n","remote: Allowed refs: all\u001b[K\n","To https://huggingface.co/CloudSource/rinna-beauty-industry\n","   85074be..5082a71  main -> main\n"]}]}]}